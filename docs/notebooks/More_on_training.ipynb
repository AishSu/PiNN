{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing the training [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Teoroo-CMC/PiNN/blob/TF2/docs/notebooks/More_on_training.ipynb)\n",
    "\n",
    "\n",
    "This notebooks covers more details on tweaking and optimizing the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PiNN & download QM9 dataset\n",
    "!pip install git+https://github.com/Teoroo-CMC/PiNN@TF2\n",
    "!mkdir -p /tmp/dsgdb9nsd && curl -sSL https://ndownloader.figshare.com/files/3195389 | tar xj -C /tmp/dsgdb9nsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, warnings\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from pinn.io import load_qm9, sparse_batch\n",
    "from pinn.networks.pinet import PiNet\n",
    "from pinn.utils import get_atomic_dress\n",
    "from pinn import get_model, get_network\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "index_warning = 'Converting sparse IndexedSlices'\n",
    "warnings.filterwarnings('ignore', index_warning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing the pipeline\n",
    "### Caching\n",
    "Caching stores the decoded dataset in the memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the purpose of testing, we use only 1000 samples from QM9\n",
    "filelist = glob('/tmp/dsgdb9nsd/*.xyz')[:1000]\n",
    "dataset = lambda: load_qm9(filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.7 ms ± 2.14 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "ds = dataset().repeat().apply(sparse_batch(100))\n",
    "tensors = ds.as_numpy_iterator()\n",
    "for i in range(10):\n",
    "    next(tensors) # \"Warm up\" the graph\n",
    "%timeit next(tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This speed indicates the IO limit of our current setting.\n",
    "\n",
    "Now let's cache the dataset to the memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324 µs ± 6.7 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "ds = dataset().cache().repeat().apply(sparse_batch(100))\n",
    "tensors = ds.as_numpy_iterator()\n",
    "for i in range(10):\n",
    "    next(tensors) # \"Warm up\" the graph\n",
    "%timeit next(tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "You might also see a notable difference in the performance with and without preprocessing. This is especially helpful when you are training with GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.9 ms ± 1.51 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "pinet = PiNet()\n",
    "ds = dataset().cache().repeat().apply(sparse_batch(100))\n",
    "tensors = ds.as_numpy_iterator()\n",
    "for i in range(10):\n",
    "    pinet(next(tensors)) # \"Warm up\" the graph\n",
    "%timeit pinet(next(tensors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/yunqi/.miniconda/envs/pinn-tf2/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "632 µs ± 158 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "pinet = PiNet()\n",
    "ds = dataset().cache().repeat().apply(sparse_batch(100)).map(pinet.preprocess)\n",
    "tensors = ds.as_numpy_iterator()\n",
    "for i in range(10):\n",
    "    next(tensors) # \"Warm up\" the graph\n",
    "%timeit next(tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can even cache the preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238 µs ± 26.4 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "pinet = PiNet()\n",
    "ds = dataset().apply(sparse_batch(100)).map(pinet.preprocess).cache().repeat()\n",
    "tensors = ds.as_numpy_iterator()\n",
    "for i in range(10):\n",
    "    next(tensors) # \"Warm up\" the graph\n",
    "%timeit next(tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atomic dress\n",
    "Scaling and aligning the labels can \n",
    "enhance the performance of the models, and avoid numerical instability.\n",
    "For datasets like QM9, we can assign an atomic energy to each atom according\n",
    "to their elements to approximate the total energy. This can be done by a simple \n",
    "linear regression. We provide a simple tool to generate such \"atomic dresses\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = glob('/home/yunqi/datasets/QM9/dsgdb9nsd/*.xyz')\n",
    "dataset = lambda: load_qm9(filelist, splits={'train':8, 'test':2})\n",
    "dress, error = get_atomic_dress(dataset()['train'],[1,6,7,8,9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the atomic dress converts the QM9 energies to a \"normal\" distribution.\n",
    "It also gives us some ideas about the relative distribution of energies, and \n",
    "how much our neural network improves from the naive guess of the atomic dress.\n",
    "\n",
    "After applying the atomic dress, it turns out that the distribution of our training set is only about 0.05 Hartree, or 30 kcal/mol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: -0.6037955907456657,\n",
       " 6: -38.07400403609262,\n",
       " 7: -54.749249586426636,\n",
       " 8: -75.22549929252084,\n",
       " 9: -99.86648045453954}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(error,50)\n",
    "dress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with the optimized pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/PiNet_QM9_pipeline', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 500, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "!rm -rf /tmp/PiNet_QM9_pipeline\n",
    "params = {'model_dir': '/tmp/PiNet_QM9_pipeline',\n",
    "          'network': {\n",
    "              'name': 'PiNet',\n",
    "              'params': {\n",
    "                  'atom_types':[1, 6, 7, 8, 9],\n",
    "              },\n",
    "          },\n",
    "          'model': {\n",
    "              'name': 'potential_model',\n",
    "              'params': {\n",
    "                  'learning_rate': 1e-3, # Relatively large learning rate\n",
    "                  'e_scale': 627.5, # Here we scale the model to kcal/mol\n",
    "                  'e_dress': dress\n",
    "              }\n",
    "          }\n",
    "         }\n",
    "\n",
    "# The logging behavior of estimator can be controlled here\n",
    "config = tf.estimator.RunConfig(log_step_count_steps=500)\n",
    "\n",
    "# Preprocessing the datasets\n",
    "model = get_model(params, config=config)\n",
    "network = get_network(model.params['network'])\n",
    "train = lambda: dataset()['train'].apply(sparse_batch(100)).map(network.preprocess).cache().repeat().shuffle(100)\n",
    "test = lambda: dataset()['test'].apply(sparse_batch(100))\n",
    "\n",
    "# Running specs\n",
    "train_spec = tf.estimator.TrainSpec(input_fn=train, max_steps=1e4)\n",
    "eval_spec = tf.estimator.EvalSpec(input_fn=test, steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "WARNING:tensorflow:From /home/yunqi/.miniconda/envs/pinn-tf2/lib/python3.9/site-packages/tensorflow/python/training/training_util.py:235: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "12112 trainable vaiabless, training with float32 precision.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/PiNet_QM9_pipeline/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 1559.4027, step = 0\n",
      "INFO:tensorflow:global_step/sec: 10.6875\n",
      "INFO:tensorflow:loss = 337.4884, step = 500 (46.787 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.153\n",
      "INFO:tensorflow:loss = 152.51575, step = 1000 (44.829 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0422\n",
      "INFO:tensorflow:loss = 173.1303, step = 1500 (19.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7495\n",
      "INFO:tensorflow:loss = 153.39145, step = 2000 (19.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7858\n",
      "INFO:tensorflow:loss = 148.38979, step = 2500 (19.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.8163\n",
      "INFO:tensorflow:loss = 81.96442, step = 3000 (19.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4343\n",
      "INFO:tensorflow:loss = 116.210754, step = 3500 (19.657 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3826\n",
      "INFO:tensorflow:loss = 117.03713, step = 4000 (19.699 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.9126\n",
      "INFO:tensorflow:loss = 92.58886, step = 4500 (20.071 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.8323\n",
      "INFO:tensorflow:loss = 60.64186, step = 5000 (19.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.8798\n",
      "INFO:tensorflow:loss = 121.45177, step = 5500 (19.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5767\n",
      "INFO:tensorflow:loss = 80.181175, step = 6000 (19.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.8342\n",
      "INFO:tensorflow:loss = 75.73455, step = 6500 (19.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4874\n",
      "INFO:tensorflow:loss = 56.026684, step = 7000 (19.618 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3525\n",
      "INFO:tensorflow:loss = 77.188095, step = 7500 (19.720 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5219\n",
      "INFO:tensorflow:loss = 93.46415, step = 8000 (19.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.36\n",
      "INFO:tensorflow:loss = 117.36995, step = 8500 (19.714 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1999\n",
      "INFO:tensorflow:loss = 117.34299, step = 9000 (19.842 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1035\n",
      "INFO:tensorflow:loss = 44.533867, step = 9500 (19.917 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 10000...\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/PiNet_QM9_pipeline/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 10000...\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-05-31T00:59:04\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/PiNet_QM9_pipeline/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Inference Time : 10.76729s\n",
      "INFO:tensorflow:Finished evaluation at 2021-05-31-00:59:15\n",
      "INFO:tensorflow:Saving dict for global step 10000: METRICS/E_LOSS = 119.6964, METRICS/E_MAE = 7.947343, METRICS/E_RMSE = 10.940587, global_step = 10000, loss = 119.6964\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: /tmp/PiNet_QM9_pipeline/model.ckpt-10000\n",
      "INFO:tensorflow:Loss for final step: 107.874664.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'METRICS/E_LOSS': 119.6964,\n",
       "  'METRICS/E_MAE': 7.947343,\n",
       "  'METRICS/E_RMSE': 10.940587,\n",
       "  'loss': 119.6964,\n",
       "  'global_step': 10000},\n",
       " [])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.estimator.train_and_evaluate(model, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring\n",
    "It's recommended to monitor the training with Tensorboard instead of the stdout here.  \n",
    "Try `tensorboard --logdir /tmp`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelization with tf.Estimator\n",
    "\n",
    "The estimator api makes it extremely easy to train on multiple GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-167cba358adc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# suppose you have two cards\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdistribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMirroredStrategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRunConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_distribute\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdistribution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda/envs/pinn-tf2/lib/python3.9/site-packages/tensorflow/python/distribute/mirrored_strategy.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, devices, cross_device_ops)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_device_ops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m     extended = MirroredExtended(\n\u001b[0m\u001b[1;32m    282\u001b[0m         self, devices=devices, cross_device_ops=cross_device_ops)\n\u001b[1;32m    283\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMirroredStrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextended\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda/envs/pinn-tf2/lib/python3.9/site-packages/tensorflow/python/distribute/mirrored_strategy.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, container_strategy, devices, cross_device_ops)\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMirroredExtended\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontainer_strategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0mdevices\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_device_list_single_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m         raise RuntimeError(\"In-graph multi-worker training with \"\n\u001b[1;32m    317\u001b[0m                            \"`MirroredStrategy` is not supported in eager mode.\")\n",
      "\u001b[0;32m~/.miniconda/envs/pinn-tf2/lib/python3.9/site-packages/tensorflow/python/distribute/mirrored_strategy.py\u001b[0m in \u001b[0;36m_is_device_list_single_worker\u001b[0;34m(devices)\u001b[0m\n\u001b[1;32m     69\u001b[0m   \"\"\"\n\u001b[1;32m     70\u001b[0m   \u001b[0mspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogicalDevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mspecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_device\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDeviceSpec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "# suppose you have two cards\n",
    "distribution = tf.distribute.MirroredStrategy(2)\n",
    "config = tf.estimator.RunConfig(train_distribute=distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Congratulations! You can now train atomic neural networks with \n",
    "state-of-the-art accuracy and speed.\n",
    "\n",
    "\n",
    "But there's more. With PiNN, the components of ANNs are modulized.\n",
    "Read the following notebooks to see how you can build your own ANN. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinn-tf2",
   "language": "python",
   "name": "pinn-tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
